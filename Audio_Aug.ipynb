{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audio_Aug.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HrithikNambiar/COVID-19-Cough-Detection/blob/main/Audio_Aug.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uRibeMmA6m7"
      },
      "source": [
        "## Installing necessary libraries and data \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOZQls6ZXFHs",
        "outputId": "9799ecc6-07a7-49e7-8ba7-2638949cdc3d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YGmbzdr0KCf"
      },
      "source": [
        "#run the code below to make a copy of the data and copy it into the cloned repo\n",
        "# %cd /content/drive/MyDrive/InterspeechParalinguisticsChallenge2021/ComParE2021_CCS\n",
        "# %cp -av dist dist_copy "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK54Wh4UCmQb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb086913-d2b1-4978-a9f7-9aea87fef174"
      },
      "source": [
        "cd /content/gdrive/MyDrive/ComParE2021"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/1a6R2J7y9rkZWY_SyloMCwmm8qdQAliCz/ComParE2021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_eHI4q5CL96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b53b5693-ceda-4bb6-c52a-a671ff33bf60"
      },
      "source": [
        "!pip install pydub\n",
        "!pip install audiomentations\n",
        "!pip install arff\n",
        "!pip install -U scikit-learn scipy matplotlib\n",
        "!pip install -U PyYAML\n",
        "!pip install audio2numpy\n",
        "!pip install sounddevice"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/a6/53/d78dc063216e62fc55f6b2eebb447f6a4b0a59f55c8406376f76bf959b08/pydub-0.25.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Collecting audiomentations\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/e1/3078fe444be2a100d804ee1296115367c27fa1dfa6298bf4155f77345822/audiomentations-0.16.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from audiomentations) (1.19.5)\n",
            "Requirement already satisfied: librosa<=0.8.0,>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from audiomentations) (0.8.0)\n",
            "Requirement already satisfied: scipy<1.6.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from audiomentations) (1.4.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (1.3.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (0.51.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (0.22.2.post1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (2.1.9)\n",
            "Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (0.10.3.post1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa<=0.8.0,>=0.6.1->audiomentations) (0.2.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (1.4.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (20.9)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa<=0.8.0,>=0.6.1->audiomentations) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa<=0.8.0,>=0.6.1->audiomentations) (54.0.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.9.0->librosa<=0.8.0,>=0.6.1->audiomentations) (1.14.5)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa<=0.8.0,>=0.6.1->audiomentations) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pooch>=1.0->librosa<=0.8.0,>=0.6.1->audiomentations) (2.4.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa<=0.8.0,>=0.6.1->audiomentations) (2.20)\n",
            "Installing collected packages: audiomentations\n",
            "Successfully installed audiomentations-0.16.0\n",
            "Collecting arff\n",
            "  Downloading https://files.pythonhosted.org/packages/50/de/62d4446c5a6e459052c2f2d9490c370ddb6abc0766547b4cef585913598d/arff-0.9.tar.gz\n",
            "Building wheels for collected packages: arff\n",
            "  Building wheel for arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for arff: filename=arff-0.9-cp37-none-any.whl size=4970 sha256=fd5bf9e96c8be94b8934b1ed7f7ea29c01643f51cb4b15d8fc9cb4979be9092c\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/d0/70/2c73afedd3ac25c6085b528742c69b9587cbdfa67e5194583b\n",
            "Successfully built arff\n",
            "Installing collected packages: arff\n",
            "Successfully installed arff-0.9\n",
            "Collecting scikit-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/74/eb899f41d55f957e2591cde5528e75871f817d9fb46d4732423ecaca736d/scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3MB 1.5MB/s \n",
            "\u001b[?25hCollecting scipy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/3a/9e0649ab2d5ade703baa70ef980aa08739226e5d6a642f084bb201a92fc2/scipy-1.6.1-cp37-cp37m-manylinux1_x86_64.whl (27.4MB)\n",
            "\u001b[K     |████████████████████████████████| 27.4MB 90kB/s \n",
            "\u001b[?25hCollecting matplotlib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/3d/db9a6b3c83c9511301152dbb64a029c3a4313c86eaef12c237b13ecf91d6/matplotlib-3.3.4-cp37-cp37m-manylinux1_x86_64.whl (11.5MB)\n",
            "\u001b[K     |████████████████████████████████| 11.6MB 43.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "\u001b[31mERROR: audiomentations 0.16.0 has requirement scipy<1.6.0,>=1.0.0, but you'll have scipy 1.6.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy, threadpoolctl, scikit-learn, matplotlib\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "Successfully installed matplotlib-3.3.4 scikit-learn-0.24.1 scipy-1.6.1 threadpoolctl-2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting PyYAML\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\r\u001b[K     |▌                               | 10kB 14.9MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 9.4MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 8.0MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 7.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 4.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 81kB 5.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 102kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 112kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 122kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 133kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 143kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 153kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 163kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 174kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 184kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 194kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 204kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 215kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 225kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 235kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 245kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 256kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 266kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 276kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 286kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 296kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 307kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 317kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 327kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 337kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 348kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 358kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 368kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 378kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 389kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 399kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 409kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 419kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 430kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 440kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 450kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 460kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 471kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 481kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 491kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 501kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 512kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 522kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 532kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 542kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 552kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 563kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 573kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 583kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 593kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 604kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 614kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 624kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 634kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 645kB 4.4MB/s \n",
            "\u001b[?25hInstalling collected packages: PyYAML\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-5.4.1\n",
            "Collecting audio2numpy\n",
            "  Downloading https://files.pythonhosted.org/packages/a2/c6/b056256f9aa7c25b051fde1c4249a83f9e331cb84b8de409cc0886a11ba5/audio2numpy-0.1.2-py3-none-any.whl\n",
            "Collecting ffmpeg\n",
            "  Downloading https://files.pythonhosted.org/packages/f0/cc/3b7408b8ecf7c1d20ad480c3eaed7619857bf1054b690226e906fdf14258/ffmpeg-1.4.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from audio2numpy) (1.19.5)\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-cp37-none-any.whl size=6083 sha256=cc23771814b60a19d31cfbfc22c1defacc05bbba1ff1c3da33ca4fd53d9c1511\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/68/c3/a05a35f647ba871e5572b9bbfc0b95fd1c6637a2219f959e7a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg, audio2numpy\n",
            "Successfully installed audio2numpy-0.1.2 ffmpeg-1.4\n",
            "Collecting sounddevice\n",
            "  Downloading https://files.pythonhosted.org/packages/3d/e9/cf30f70b81c1a7fa97598d2e89fddb16ab798ca6d64182aa8cd2d66794a4/sounddevice-0.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.7/dist-packages (from sounddevice) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from CFFI>=1.0->sounddevice) (2.20)\n",
            "Installing collected packages: sounddevice\n",
            "Successfully installed sounddevice-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vnst-YMKBEQr"
      },
      "source": [
        "## Run the baseline code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBHRoy4N9sxW",
        "outputId": "40642c45-875d-4ca0-8d8d-60d5f151c2f4"
      },
      "source": [
        "%%bash\n",
        "python -m src.svm openXBoW"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6294398907103825\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.84      0.97      0.90       183\n",
            "    positive       0.70      0.29      0.41        48\n",
            "\n",
            "    accuracy                           0.83       231\n",
            "   macro avg       0.77      0.63      0.66       231\n",
            "weighted avg       0.81      0.83      0.80       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[177   6]\n",
            " [ 34  14]]\n",
            "Generating test predictions for optimised parameters {'estimator': 'LinearSVC(C=0.01, max_iter=10000, random_state=42)', 'estimator__C': '0.01', 'estimator__class_weight': 'None', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'None'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.60724043715847\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.84      0.80      0.82       183\n",
            "    positive       0.35      0.42      0.38        48\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.59      0.61      0.60       231\n",
            "weighted avg       0.74      0.72      0.73       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[146  37]\n",
            " [ 28  20]]\n",
            "Generating test predictions for optimised parameters {'estimator': 'LinearSVC(C=0.001, max_iter=10000, random_state=42)', 'estimator__C': '0.001', 'estimator__class_weight': 'None', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6234631147540983\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.84      0.93      0.88       183\n",
            "    positive       0.56      0.31      0.40        48\n",
            "\n",
            "    accuracy                           0.81       231\n",
            "   macro avg       0.70      0.62      0.64       231\n",
            "weighted avg       0.78      0.81      0.78       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[171  12]\n",
            " [ 33  15]]\n",
            "Generating test predictions for optimised parameters {'estimator': 'LinearSVC(C=0.01, max_iter=10000, random_state=42)', 'estimator__C': '0.01', 'estimator__class_weight': 'None', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'None'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6511270491803278\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.78      0.82       183\n",
            "    positive       0.38      0.52      0.44        48\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.62      0.65      0.63       231\n",
            "weighted avg       0.76      0.73      0.74       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[143  40]\n",
            " [ 23  25]]\n",
            "Generating test predictions for optimised parameters {'estimator': \"LinearSVC(C=0.001, class_weight='balanced', max_iter=10000, random_state=42)\", 'estimator__C': '0.001', 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6466871584699454\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.81      0.83       183\n",
            "    positive       0.40      0.48      0.44        48\n",
            "\n",
            "    accuracy                           0.74       231\n",
            "   macro avg       0.63      0.65      0.64       231\n",
            "weighted avg       0.76      0.74      0.75       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[149  34]\n",
            " [ 25  23]]\n",
            "Generating test predictions for optimised parameters {'estimator': \"LinearSVC(C=1e-05, class_weight='balanced', max_iter=10000, random_state=42)\", 'estimator__C': '1e-05', 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'None'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6729849726775956\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.87      0.83      0.85       183\n",
            "    positive       0.44      0.52      0.48        48\n",
            "\n",
            "    accuracy                           0.76       231\n",
            "   macro avg       0.65      0.67      0.66       231\n",
            "weighted avg       0.78      0.76      0.77       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[151  32]\n",
            " [ 23  25]]\n",
            "Generating test predictions for optimised parameters {'estimator': 'LinearSVC(C=0.001, max_iter=10000, random_state=42)', 'estimator__C': '0.001', 'estimator__class_weight': 'None', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6752049180327868\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.87      0.81      0.84       183\n",
            "    positive       0.43      0.54      0.48        48\n",
            "\n",
            "    accuracy                           0.75       231\n",
            "   macro avg       0.65      0.68      0.66       231\n",
            "weighted avg       0.78      0.75      0.76       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[148  35]\n",
            " [ 22  26]]\n",
            "Generating test predictions for optimised parameters {'estimator': \"LinearSVC(C=0.01, class_weight='balanced', max_iter=10000, random_state=42)\", 'estimator__C': '0.01', 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6642759562841529\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.87      0.79      0.83       183\n",
            "    positive       0.40      0.54      0.46        48\n",
            "\n",
            "    accuracy                           0.74       231\n",
            "   macro avg       0.63      0.66      0.64       231\n",
            "weighted avg       0.77      0.74      0.75       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[144  39]\n",
            " [ 22  26]]\n",
            "Generating test predictions for optimised parameters {'estimator': \"LinearSVC(C=0.01, class_weight='balanced', max_iter=10000, random_state=42)\", 'estimator__C': '0.01', 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6543715846994536\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.81      0.83       183\n",
            "    positive       0.41      0.50      0.45        48\n",
            "\n",
            "    accuracy                           0.74       231\n",
            "   macro avg       0.63      0.65      0.64       231\n",
            "weighted avg       0.77      0.74      0.75       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[148  35]\n",
            " [ 24  24]]\n",
            "Generating test predictions for optimised parameters {'estimator': 'LinearSVC(C=0.001, max_iter=10000, random_state=42)', 'estimator__C': '0.001', 'estimator__class_weight': 'None', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.662568306010929\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.83      0.84       183\n",
            "    positive       0.43      0.50      0.46        48\n",
            "\n",
            "    accuracy                           0.76       231\n",
            "   macro avg       0.65      0.66      0.65       231\n",
            "weighted avg       0.77      0.76      0.76       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[151  32]\n",
            " [ 24  24]]\n",
            "Generating test predictions for optimised parameters {'estimator': 'LinearSVC(C=0.01, max_iter=10000, random_state=42)', 'estimator__C': '0.01', 'estimator__class_weight': 'None', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6724726775956285\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.87      0.80      0.84       183\n",
            "    positive       0.42      0.54      0.47        48\n",
            "\n",
            "    accuracy                           0.75       231\n",
            "   macro avg       0.64      0.67      0.65       231\n",
            "weighted avg       0.78      0.75      0.76       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[147  36]\n",
            " [ 22  26]]\n",
            "Generating test predictions for optimised parameters {'estimator': 'LinearSVC(C=0.01, max_iter=10000, random_state=42)', 'estimator__C': '0.01', 'estimator__class_weight': 'None', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6623975409836066\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.85      0.93      0.89       183\n",
            "    positive       0.59      0.40      0.48        48\n",
            "\n",
            "    accuracy                           0.82       231\n",
            "   macro avg       0.72      0.66      0.68       231\n",
            "weighted avg       0.80      0.82      0.80       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[170  13]\n",
            " [ 29  19]]\n",
            "Generating test predictions for optimised parameters {'estimator': 'LinearSVC(C=0.01, max_iter=10000, random_state=42)', 'estimator__C': '0.01', 'estimator__class_weight': 'None', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'None'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6067281420765027\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.84      0.78      0.81       183\n",
            "    positive       0.34      0.44      0.38        48\n",
            "\n",
            "    accuracy                           0.71       231\n",
            "   macro avg       0.59      0.61      0.59       231\n",
            "weighted avg       0.74      0.71      0.72       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[142  41]\n",
            " [ 27  21]]\n",
            "Generating test predictions for optimised parameters {'estimator': \"LinearSVC(C=0.1, class_weight='balanced', max_iter=10000, random_state=42)\", 'estimator__C': '0.1', 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6516393442622951\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.80      0.83       183\n",
            "    positive       0.40      0.50      0.44        48\n",
            "\n",
            "    accuracy                           0.74       231\n",
            "   macro avg       0.63      0.65      0.64       231\n",
            "weighted avg       0.76      0.74      0.75       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[147  36]\n",
            " [ 24  24]]\n",
            "Generating test predictions for optimised parameters {'estimator': \"LinearSVC(C=0.1, class_weight='balanced', max_iter=10000, random_state=42)\", 'estimator__C': '0.1', 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'None'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.67400956284153\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.87      0.87       183\n",
            "    positive       0.49      0.48      0.48        48\n",
            "\n",
            "    accuracy                           0.79       231\n",
            "   macro avg       0.68      0.67      0.68       231\n",
            "weighted avg       0.79      0.79      0.79       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[159  24]\n",
            " [ 25  23]]\n",
            "Generating test predictions for optimised parameters {'estimator': \"LinearSVC(C=0.1, class_weight='balanced', max_iter=10000, random_state=42)\", 'estimator__C': '0.1', 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'None'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rhUSr2IP1HZ",
        "outputId": "7dd1ebc9-e55f-4e25-9f63-8707d278be19"
      },
      "source": [
        "%%bash\n",
        "python -m src.svm opensmile"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6139002732240437\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.85      0.75      0.79       183\n",
            "    positive       0.33      0.48      0.39        48\n",
            "\n",
            "    accuracy                           0.69       231\n",
            "   macro avg       0.59      0.61      0.59       231\n",
            "weighted avg       0.74      0.69      0.71       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[137  46]\n",
            " [ 25  23]]\n",
            "Generating test predictions for optimised parameters {'estimator': \"LinearSVC(C=0.1, class_weight='balanced', max_iter=10000, random_state=42)\", 'estimator__C': '0.1', 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHUOzZOpUyye"
      },
      "source": [
        "## Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfmGPBb0FsNo"
      },
      "source": [
        "import os\n",
        "import glob \n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "import soundfile as sf\n",
        "from pydub import AudioSegment\n",
        "from audio2numpy import open_audio\n",
        "from pydub.silence import split_on_silence\n",
        "from scipy.io.wavfile import read as read_wav\n",
        "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift,FrequencyMask\n",
        "\n",
        "from IPython.display import Audio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNE1eAAsO7ps"
      },
      "source": [
        "fname = \"/content/gdrive/MyDrive/ComParE2021/dist/wav/devel_017.wav\"\n",
        "FIG_SIZE = (15,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDNE0hHrPJpL"
      },
      "source": [
        "#Waveform of devel 001\n",
        "signal, sample_rate = librosa.load(fname, sr=16000)\n",
        "\n",
        "# WAVEFORM\n",
        "# display waveform\n",
        "plt.figure(figsize=FIG_SIZE)\n",
        "librosa.display.waveplot(signal, sample_rate, alpha=0.4)\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.title(\"Waveform\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-LllGn6X2T6"
      },
      "source": [
        "def split_file_into_chunks(fname, min_silence_len=500, silence_threshold=-40):\n",
        "  sound_file = AudioSegment.from_wav(fname)\n",
        "  audio_chunks = split_on_silence(sound_file, min_silence_len=min_silence_len, silence_thresh=silence_threshold)\n",
        "\n",
        "  for i, chunk in enumerate(audio_chunks):\n",
        "    out_file = \"chunk{0}.wav\".format(i)\n",
        "    # print(\"exporting\", out_file)\n",
        "    chunk.export(out_file, format=\"wav\")\n",
        "\n",
        "  return len(audio_chunks)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0frjpJCvj35A"
      },
      "source": [
        "os.mkdir('/content/gdrive/MyDrive/ComParE2021/data_2')\n",
        "\n",
        "os.mkdir('/content/gdrive/MyDrive/ComParE2021/data_2/train/')\n",
        "os.mkdir('/content/gdrive/MyDrive/ComParE2021/data_2/test/')\n",
        "os.mkdir('/content/gdrive/MyDrive/ComParE2021/data_2/val/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LK6-jg6aKe0"
      },
      "source": [
        "def augment_data(input_dir='/content/drive/MyDrive/ComParE2021/dist/wav', \n",
        "                 output_dir='/content/drive/MyDrive/ComParE2021/data/Augmented_train', \n",
        "                 csv_file=\"/content/drive/MyDrive/ComParE2021/dist/lab/train.csv\", \n",
        "                 csv_output_path=\"/content/gdrive/MyDrive/ComParE2021/data/train.csv\",\n",
        "                 split_files=True,\n",
        "                 augmentations=None):\n",
        "  samplerate = 16000\n",
        "  df = pd.read_csv(csv_file)\n",
        "\n",
        "  augmented_fnames = [] \n",
        "  augmented_classes = []\n",
        "\n",
        "  for f in df['filename']: \n",
        "    print(f)\n",
        "    orig_class  = df.loc[df['filename']==f]['label'].item()\n",
        "\n",
        "    if split_files: \n",
        "      audio_chunks = split_file_into_chunks(os.path.join(input_dir, f))\n",
        "\n",
        "    else:\n",
        "      sample = librosa.core.load(os.path.join(input_dir, f))[0]\n",
        "      sf.write(\"chunk0.wav\", sample,samplerate,format='wav')\n",
        "      audio_chunks = 1\n",
        "\n",
        "    if \"Gaussian_noise\" in augmentations:\n",
        "      for j in range(audio_chunks):\n",
        "        sample = librosa.core.load(f\"chunk{j}.wav\")[0]\n",
        "        augmentar = Compose([AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.010, p=1)])\n",
        "        augmented_sample = augmentar(sample, sample_rate=16000)\n",
        "        modified_fname = \"gn_\"+f[:-4]+\"_\"+str(j)+\".wav\"\n",
        "        sf.write(os.path.join(output_dir, modified_fname), augmented_sample,samplerate,format='wav')\n",
        "\n",
        "        augmented_fnames.append(modified_fname)\n",
        "        augmented_classes.append(orig_class)\n",
        "\n",
        "    if \"Shift\" in augmentations:\n",
        "      for j in range(audio_chunks):\n",
        "        sample = librosa.core.load(f\"chunk{j}.wav\")[0]\n",
        "        augmentar = Compose([Shift(min_fraction=-0.1, max_fraction=0.1,rollover=False, p=1)])\n",
        "        augmented_sample = augmentar(sample, sample_rate=16000)\n",
        "        modified_fname = \"st_\"+f[:-4]+\"_\"+str(j)+\".wav\"\n",
        "        sf.write(os.path.join(output_dir, modified_fname), augmented_sample,samplerate,format='wav')\n",
        "\n",
        "        augmented_fnames.append(modified_fname)\n",
        "        augmented_classes.append(orig_class)\n",
        "\n",
        "    if \"Frequency_Mask\" in augmentations: \n",
        "      for j in range(audio_chunks):\n",
        "        sample = librosa.core.load(f\"chunk{j}.wav\")[0]\n",
        "        augmentar = Compose([FrequencyMask(min_frequency_band=0.0, max_frequency_band=0.5, p=0.5)])\n",
        "        augmented_sample = augmentar(sample, sample_rate=16000)\n",
        "        modified_fname = \"fm_\"+f[:-4]+\"_\"+str(j)+\".wav\"\n",
        "        sf.write(os.path.join(output_dir, modified_fname), augmented_sample,samplerate,format='wav')\n",
        "\n",
        "        augmented_fnames.append(modified_fname)\n",
        "        augmented_classes.append(orig_class)\n",
        "\n",
        "    for j in range(audio_chunks):\n",
        "      sample = librosa.core.load(f\"chunk{j}.wav\")[0]\n",
        "      modified_fname = f[:-4]+\"_\"+str(j)+\".wav\"\n",
        "      sf.write(os.path.join(output_dir, modified_fname), sample,samplerate,format='wav')\n",
        "\n",
        "      augmented_fnames.append(modified_fname)\n",
        "      augmented_classes.append(orig_class)\n",
        "\n",
        "  final_df = pd.DataFrame({'filename': augmented_fnames, 'label': augmented_classes})\n",
        "  final_df.to_csv(csv_output_path, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hR4l22NqayDG",
        "outputId": "655377e5-6883-4550-8e5e-a65652876a3f"
      },
      "source": [
        "augment_data(input_dir='/content/gdrive/MyDrive/ComParE2021/dist/wav', output_dir='/content/gdrive/MyDrive/ComParE2021/data_2/train/', csv_file=\"/content/gdrive/MyDrive/ComParE2021/dist/lab/train.csv\", csv_output_path='/content/gdrive/MyDrive/ComParE2021/data_2/train.csv' ,split_files=True, augmentations=[\"Gaussian_noise\", \"Shift\", \"Frequency_Mask\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_001.wav\n",
            "train_002.wav\n",
            "train_003.wav\n",
            "train_004.wav\n",
            "train_005.wav\n",
            "train_006.wav\n",
            "train_007.wav\n",
            "train_008.wav\n",
            "train_009.wav\n",
            "train_010.wav\n",
            "train_011.wav\n",
            "train_012.wav\n",
            "train_013.wav\n",
            "train_014.wav\n",
            "train_015.wav\n",
            "train_016.wav\n",
            "train_017.wav\n",
            "train_018.wav\n",
            "train_019.wav\n",
            "train_020.wav\n",
            "train_021.wav\n",
            "train_022.wav\n",
            "train_023.wav\n",
            "train_024.wav\n",
            "train_025.wav\n",
            "train_026.wav\n",
            "train_027.wav\n",
            "train_028.wav\n",
            "train_029.wav\n",
            "train_030.wav\n",
            "train_031.wav\n",
            "train_032.wav\n",
            "train_033.wav\n",
            "train_034.wav\n",
            "train_035.wav\n",
            "train_036.wav\n",
            "train_037.wav\n",
            "train_038.wav\n",
            "train_039.wav\n",
            "train_040.wav\n",
            "train_041.wav\n",
            "train_042.wav\n",
            "train_043.wav\n",
            "train_044.wav\n",
            "train_045.wav\n",
            "train_046.wav\n",
            "train_047.wav\n",
            "train_048.wav\n",
            "train_049.wav\n",
            "train_050.wav\n",
            "train_051.wav\n",
            "train_052.wav\n",
            "train_053.wav\n",
            "train_054.wav\n",
            "train_055.wav\n",
            "train_056.wav\n",
            "train_057.wav\n",
            "train_058.wav\n",
            "train_059.wav\n",
            "train_060.wav\n",
            "train_061.wav\n",
            "train_062.wav\n",
            "train_063.wav\n",
            "train_064.wav\n",
            "train_065.wav\n",
            "train_066.wav\n",
            "train_067.wav\n",
            "train_068.wav\n",
            "train_069.wav\n",
            "train_070.wav\n",
            "train_071.wav\n",
            "train_072.wav\n",
            "train_073.wav\n",
            "train_074.wav\n",
            "train_075.wav\n",
            "train_076.wav\n",
            "train_077.wav\n",
            "train_078.wav\n",
            "train_079.wav\n",
            "train_080.wav\n",
            "train_081.wav\n",
            "train_082.wav\n",
            "train_083.wav\n",
            "train_084.wav\n",
            "train_085.wav\n",
            "train_086.wav\n",
            "train_087.wav\n",
            "train_088.wav\n",
            "train_089.wav\n",
            "train_090.wav\n",
            "train_091.wav\n",
            "train_092.wav\n",
            "train_093.wav\n",
            "train_094.wav\n",
            "train_095.wav\n",
            "train_096.wav\n",
            "train_097.wav\n",
            "train_098.wav\n",
            "train_099.wav\n",
            "train_100.wav\n",
            "train_101.wav\n",
            "train_102.wav\n",
            "train_103.wav\n",
            "train_104.wav\n",
            "train_105.wav\n",
            "train_106.wav\n",
            "train_107.wav\n",
            "train_108.wav\n",
            "train_109.wav\n",
            "train_110.wav\n",
            "train_111.wav\n",
            "train_112.wav\n",
            "train_113.wav\n",
            "train_114.wav\n",
            "train_115.wav\n",
            "train_116.wav\n",
            "train_117.wav\n",
            "train_118.wav\n",
            "train_119.wav\n",
            "train_120.wav\n",
            "train_121.wav\n",
            "train_122.wav\n",
            "train_123.wav\n",
            "train_124.wav\n",
            "train_125.wav\n",
            "train_126.wav\n",
            "train_127.wav\n",
            "train_128.wav\n",
            "train_129.wav\n",
            "train_130.wav\n",
            "train_131.wav\n",
            "train_132.wav\n",
            "train_133.wav\n",
            "train_134.wav\n",
            "train_135.wav\n",
            "train_136.wav\n",
            "train_137.wav\n",
            "train_138.wav\n",
            "train_139.wav\n",
            "train_140.wav\n",
            "train_141.wav\n",
            "train_142.wav\n",
            "train_143.wav\n",
            "train_144.wav\n",
            "train_145.wav\n",
            "train_146.wav\n",
            "train_147.wav\n",
            "train_148.wav\n",
            "train_149.wav\n",
            "train_150.wav\n",
            "train_151.wav\n",
            "train_152.wav\n",
            "train_153.wav\n",
            "train_154.wav\n",
            "train_155.wav\n",
            "train_156.wav\n",
            "train_157.wav\n",
            "train_158.wav\n",
            "train_159.wav\n",
            "train_160.wav\n",
            "train_161.wav\n",
            "train_162.wav\n",
            "train_163.wav\n",
            "train_164.wav\n",
            "train_165.wav\n",
            "train_166.wav\n",
            "train_167.wav\n",
            "train_168.wav\n",
            "train_169.wav\n",
            "train_170.wav\n",
            "train_171.wav\n",
            "train_172.wav\n",
            "train_173.wav\n",
            "train_174.wav\n",
            "train_175.wav\n",
            "train_176.wav\n",
            "train_177.wav\n",
            "train_178.wav\n",
            "train_179.wav\n",
            "train_180.wav\n",
            "train_181.wav\n",
            "train_182.wav\n",
            "train_183.wav\n",
            "train_184.wav\n",
            "train_185.wav\n",
            "train_186.wav\n",
            "train_187.wav\n",
            "train_188.wav\n",
            "train_189.wav\n",
            "train_190.wav\n",
            "train_191.wav\n",
            "train_192.wav\n",
            "train_193.wav\n",
            "train_194.wav\n",
            "train_195.wav\n",
            "train_196.wav\n",
            "train_197.wav\n",
            "train_198.wav\n",
            "train_199.wav\n",
            "train_200.wav\n",
            "train_201.wav\n",
            "train_202.wav\n",
            "train_203.wav\n",
            "train_204.wav\n",
            "train_205.wav\n",
            "train_206.wav\n",
            "train_207.wav\n",
            "train_208.wav\n",
            "train_209.wav\n",
            "train_210.wav\n",
            "train_211.wav\n",
            "train_212.wav\n",
            "train_213.wav\n",
            "train_214.wav\n",
            "train_215.wav\n",
            "train_216.wav\n",
            "train_217.wav\n",
            "train_218.wav\n",
            "train_219.wav\n",
            "train_220.wav\n",
            "train_221.wav\n",
            "train_222.wav\n",
            "train_223.wav\n",
            "train_224.wav\n",
            "train_225.wav\n",
            "train_226.wav\n",
            "train_227.wav\n",
            "train_228.wav\n",
            "train_229.wav\n",
            "train_230.wav\n",
            "train_231.wav\n",
            "train_232.wav\n",
            "train_233.wav\n",
            "train_234.wav\n",
            "train_235.wav\n",
            "train_236.wav\n",
            "train_237.wav\n",
            "train_238.wav\n",
            "train_239.wav\n",
            "train_240.wav\n",
            "train_241.wav\n",
            "train_242.wav\n",
            "train_243.wav\n",
            "train_244.wav\n",
            "train_245.wav\n",
            "train_246.wav\n",
            "train_247.wav\n",
            "train_248.wav\n",
            "train_249.wav\n",
            "train_250.wav\n",
            "train_251.wav\n",
            "train_252.wav\n",
            "train_253.wav\n",
            "train_254.wav\n",
            "train_255.wav\n",
            "train_256.wav\n",
            "train_257.wav\n",
            "train_258.wav\n",
            "train_259.wav\n",
            "train_260.wav\n",
            "train_261.wav\n",
            "train_262.wav\n",
            "train_263.wav\n",
            "train_264.wav\n",
            "train_265.wav\n",
            "train_266.wav\n",
            "train_267.wav\n",
            "train_268.wav\n",
            "train_269.wav\n",
            "train_270.wav\n",
            "train_271.wav\n",
            "train_272.wav\n",
            "train_273.wav\n",
            "train_274.wav\n",
            "train_275.wav\n",
            "train_276.wav\n",
            "train_277.wav\n",
            "train_278.wav\n",
            "train_279.wav\n",
            "train_280.wav\n",
            "train_281.wav\n",
            "train_282.wav\n",
            "train_283.wav\n",
            "train_284.wav\n",
            "train_285.wav\n",
            "train_286.wav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6AtY20thm6r",
        "outputId": "3d1e5021-af83-4928-c246-97ad9e73f053"
      },
      "source": [
        "augment_data(input_dir='/content/gdrive/MyDrive/ComParE2021/dist/wav', output_dir='/content/gdrive/MyDrive/ComParE2021/data_2/test/', csv_file=\"/content/gdrive/MyDrive/ComParE2021/dist/lab/test.csv\", csv_output_path='/content/gdrive/MyDrive/ComParE2021/data_2/test.csv' ,split_files=True, augmentations=[\"None\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_001.wav\n",
            "test_002.wav\n",
            "test_003.wav\n",
            "test_004.wav\n",
            "test_005.wav\n",
            "test_006.wav\n",
            "test_007.wav\n",
            "test_008.wav\n",
            "test_009.wav\n",
            "test_010.wav\n",
            "test_011.wav\n",
            "test_012.wav\n",
            "test_013.wav\n",
            "test_014.wav\n",
            "test_015.wav\n",
            "test_016.wav\n",
            "test_017.wav\n",
            "test_018.wav\n",
            "test_019.wav\n",
            "test_020.wav\n",
            "test_021.wav\n",
            "test_022.wav\n",
            "test_023.wav\n",
            "test_024.wav\n",
            "test_025.wav\n",
            "test_026.wav\n",
            "test_027.wav\n",
            "test_028.wav\n",
            "test_029.wav\n",
            "test_030.wav\n",
            "test_031.wav\n",
            "test_032.wav\n",
            "test_033.wav\n",
            "test_034.wav\n",
            "test_035.wav\n",
            "test_036.wav\n",
            "test_037.wav\n",
            "test_038.wav\n",
            "test_039.wav\n",
            "test_040.wav\n",
            "test_041.wav\n",
            "test_042.wav\n",
            "test_043.wav\n",
            "test_044.wav\n",
            "test_045.wav\n",
            "test_046.wav\n",
            "test_047.wav\n",
            "test_048.wav\n",
            "test_049.wav\n",
            "test_050.wav\n",
            "test_051.wav\n",
            "test_052.wav\n",
            "test_053.wav\n",
            "test_054.wav\n",
            "test_055.wav\n",
            "test_056.wav\n",
            "test_057.wav\n",
            "test_058.wav\n",
            "test_059.wav\n",
            "test_060.wav\n",
            "test_061.wav\n",
            "test_062.wav\n",
            "test_063.wav\n",
            "test_064.wav\n",
            "test_065.wav\n",
            "test_066.wav\n",
            "test_067.wav\n",
            "test_068.wav\n",
            "test_069.wav\n",
            "test_070.wav\n",
            "test_071.wav\n",
            "test_072.wav\n",
            "test_073.wav\n",
            "test_074.wav\n",
            "test_075.wav\n",
            "test_076.wav\n",
            "test_077.wav\n",
            "test_078.wav\n",
            "test_079.wav\n",
            "test_080.wav\n",
            "test_081.wav\n",
            "test_082.wav\n",
            "test_083.wav\n",
            "test_084.wav\n",
            "test_085.wav\n",
            "test_086.wav\n",
            "test_087.wav\n",
            "test_088.wav\n",
            "test_089.wav\n",
            "test_090.wav\n",
            "test_091.wav\n",
            "test_092.wav\n",
            "test_093.wav\n",
            "test_094.wav\n",
            "test_095.wav\n",
            "test_096.wav\n",
            "test_097.wav\n",
            "test_098.wav\n",
            "test_099.wav\n",
            "test_100.wav\n",
            "test_101.wav\n",
            "test_102.wav\n",
            "test_103.wav\n",
            "test_104.wav\n",
            "test_105.wav\n",
            "test_106.wav\n",
            "test_107.wav\n",
            "test_108.wav\n",
            "test_109.wav\n",
            "test_110.wav\n",
            "test_111.wav\n",
            "test_112.wav\n",
            "test_113.wav\n",
            "test_114.wav\n",
            "test_115.wav\n",
            "test_116.wav\n",
            "test_117.wav\n",
            "test_118.wav\n",
            "test_119.wav\n",
            "test_120.wav\n",
            "test_121.wav\n",
            "test_122.wav\n",
            "test_123.wav\n",
            "test_124.wav\n",
            "test_125.wav\n",
            "test_126.wav\n",
            "test_127.wav\n",
            "test_128.wav\n",
            "test_129.wav\n",
            "test_130.wav\n",
            "test_131.wav\n",
            "test_132.wav\n",
            "test_133.wav\n",
            "test_134.wav\n",
            "test_135.wav\n",
            "test_136.wav\n",
            "test_137.wav\n",
            "test_138.wav\n",
            "test_139.wav\n",
            "test_140.wav\n",
            "test_141.wav\n",
            "test_142.wav\n",
            "test_143.wav\n",
            "test_144.wav\n",
            "test_145.wav\n",
            "test_146.wav\n",
            "test_147.wav\n",
            "test_148.wav\n",
            "test_149.wav\n",
            "test_150.wav\n",
            "test_151.wav\n",
            "test_152.wav\n",
            "test_153.wav\n",
            "test_154.wav\n",
            "test_155.wav\n",
            "test_156.wav\n",
            "test_157.wav\n",
            "test_158.wav\n",
            "test_159.wav\n",
            "test_160.wav\n",
            "test_161.wav\n",
            "test_162.wav\n",
            "test_163.wav\n",
            "test_164.wav\n",
            "test_165.wav\n",
            "test_166.wav\n",
            "test_167.wav\n",
            "test_168.wav\n",
            "test_169.wav\n",
            "test_170.wav\n",
            "test_171.wav\n",
            "test_172.wav\n",
            "test_173.wav\n",
            "test_174.wav\n",
            "test_175.wav\n",
            "test_176.wav\n",
            "test_177.wav\n",
            "test_178.wav\n",
            "test_179.wav\n",
            "test_180.wav\n",
            "test_181.wav\n",
            "test_182.wav\n",
            "test_183.wav\n",
            "test_184.wav\n",
            "test_185.wav\n",
            "test_186.wav\n",
            "test_187.wav\n",
            "test_188.wav\n",
            "test_189.wav\n",
            "test_190.wav\n",
            "test_191.wav\n",
            "test_192.wav\n",
            "test_193.wav\n",
            "test_194.wav\n",
            "test_195.wav\n",
            "test_196.wav\n",
            "test_197.wav\n",
            "test_198.wav\n",
            "test_199.wav\n",
            "test_200.wav\n",
            "test_201.wav\n",
            "test_202.wav\n",
            "test_203.wav\n",
            "test_204.wav\n",
            "test_205.wav\n",
            "test_206.wav\n",
            "test_207.wav\n",
            "test_208.wav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYjv1bHqmT8i",
        "outputId": "18924daf-b38f-44bb-f21c-39d6dedc3dc8"
      },
      "source": [
        "augment_data(input_dir='/content/gdrive/MyDrive/ComParE2021/dist/wav', output_dir='/content/gdrive/MyDrive/ComParE2021/data_2/val/', csv_file=\"/content/gdrive/MyDrive/ComParE2021/dist/lab/devel.csv\", csv_output_path='/content/gdrive/MyDrive/ComParE2021/data_2/val.csv' ,split_files=True, augmentations=[\"None\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "devel_001.wav\n",
            "devel_002.wav\n",
            "devel_003.wav\n",
            "devel_004.wav\n",
            "devel_005.wav\n",
            "devel_006.wav\n",
            "devel_007.wav\n",
            "devel_008.wav\n",
            "devel_009.wav\n",
            "devel_010.wav\n",
            "devel_011.wav\n",
            "devel_012.wav\n",
            "devel_013.wav\n",
            "devel_014.wav\n",
            "devel_015.wav\n",
            "devel_016.wav\n",
            "devel_017.wav\n",
            "devel_018.wav\n",
            "devel_019.wav\n",
            "devel_020.wav\n",
            "devel_021.wav\n",
            "devel_022.wav\n",
            "devel_023.wav\n",
            "devel_024.wav\n",
            "devel_025.wav\n",
            "devel_026.wav\n",
            "devel_027.wav\n",
            "devel_028.wav\n",
            "devel_029.wav\n",
            "devel_030.wav\n",
            "devel_031.wav\n",
            "devel_032.wav\n",
            "devel_033.wav\n",
            "devel_034.wav\n",
            "devel_035.wav\n",
            "devel_036.wav\n",
            "devel_037.wav\n",
            "devel_038.wav\n",
            "devel_039.wav\n",
            "devel_040.wav\n",
            "devel_041.wav\n",
            "devel_042.wav\n",
            "devel_043.wav\n",
            "devel_044.wav\n",
            "devel_045.wav\n",
            "devel_046.wav\n",
            "devel_047.wav\n",
            "devel_048.wav\n",
            "devel_049.wav\n",
            "devel_050.wav\n",
            "devel_051.wav\n",
            "devel_052.wav\n",
            "devel_053.wav\n",
            "devel_054.wav\n",
            "devel_055.wav\n",
            "devel_056.wav\n",
            "devel_057.wav\n",
            "devel_058.wav\n",
            "devel_059.wav\n",
            "devel_060.wav\n",
            "devel_061.wav\n",
            "devel_062.wav\n",
            "devel_063.wav\n",
            "devel_064.wav\n",
            "devel_065.wav\n",
            "devel_066.wav\n",
            "devel_067.wav\n",
            "devel_068.wav\n",
            "devel_069.wav\n",
            "devel_070.wav\n",
            "devel_071.wav\n",
            "devel_072.wav\n",
            "devel_073.wav\n",
            "devel_074.wav\n",
            "devel_075.wav\n",
            "devel_076.wav\n",
            "devel_077.wav\n",
            "devel_078.wav\n",
            "devel_079.wav\n",
            "devel_080.wav\n",
            "devel_081.wav\n",
            "devel_082.wav\n",
            "devel_083.wav\n",
            "devel_084.wav\n",
            "devel_085.wav\n",
            "devel_086.wav\n",
            "devel_087.wav\n",
            "devel_088.wav\n",
            "devel_089.wav\n",
            "devel_090.wav\n",
            "devel_091.wav\n",
            "devel_092.wav\n",
            "devel_093.wav\n",
            "devel_094.wav\n",
            "devel_095.wav\n",
            "devel_096.wav\n",
            "devel_097.wav\n",
            "devel_098.wav\n",
            "devel_099.wav\n",
            "devel_100.wav\n",
            "devel_101.wav\n",
            "devel_102.wav\n",
            "devel_103.wav\n",
            "devel_104.wav\n",
            "devel_105.wav\n",
            "devel_106.wav\n",
            "devel_107.wav\n",
            "devel_108.wav\n",
            "devel_109.wav\n",
            "devel_110.wav\n",
            "devel_111.wav\n",
            "devel_112.wav\n",
            "devel_113.wav\n",
            "devel_114.wav\n",
            "devel_115.wav\n",
            "devel_116.wav\n",
            "devel_117.wav\n",
            "devel_118.wav\n",
            "devel_119.wav\n",
            "devel_120.wav\n",
            "devel_121.wav\n",
            "devel_122.wav\n",
            "devel_123.wav\n",
            "devel_124.wav\n",
            "devel_125.wav\n",
            "devel_126.wav\n",
            "devel_127.wav\n",
            "devel_128.wav\n",
            "devel_129.wav\n",
            "devel_130.wav\n",
            "devel_131.wav\n",
            "devel_132.wav\n",
            "devel_133.wav\n",
            "devel_134.wav\n",
            "devel_135.wav\n",
            "devel_136.wav\n",
            "devel_137.wav\n",
            "devel_138.wav\n",
            "devel_139.wav\n",
            "devel_140.wav\n",
            "devel_141.wav\n",
            "devel_142.wav\n",
            "devel_143.wav\n",
            "devel_144.wav\n",
            "devel_145.wav\n",
            "devel_146.wav\n",
            "devel_147.wav\n",
            "devel_148.wav\n",
            "devel_149.wav\n",
            "devel_150.wav\n",
            "devel_151.wav\n",
            "devel_152.wav\n",
            "devel_153.wav\n",
            "devel_154.wav\n",
            "devel_155.wav\n",
            "devel_156.wav\n",
            "devel_157.wav\n",
            "devel_158.wav\n",
            "devel_159.wav\n",
            "devel_160.wav\n",
            "devel_161.wav\n",
            "devel_162.wav\n",
            "devel_163.wav\n",
            "devel_164.wav\n",
            "devel_165.wav\n",
            "devel_166.wav\n",
            "devel_167.wav\n",
            "devel_168.wav\n",
            "devel_169.wav\n",
            "devel_170.wav\n",
            "devel_171.wav\n",
            "devel_172.wav\n",
            "devel_173.wav\n",
            "devel_174.wav\n",
            "devel_175.wav\n",
            "devel_176.wav\n",
            "devel_177.wav\n",
            "devel_178.wav\n",
            "devel_179.wav\n",
            "devel_180.wav\n",
            "devel_181.wav\n",
            "devel_182.wav\n",
            "devel_183.wav\n",
            "devel_184.wav\n",
            "devel_185.wav\n",
            "devel_186.wav\n",
            "devel_187.wav\n",
            "devel_188.wav\n",
            "devel_189.wav\n",
            "devel_190.wav\n",
            "devel_191.wav\n",
            "devel_192.wav\n",
            "devel_193.wav\n",
            "devel_194.wav\n",
            "devel_195.wav\n",
            "devel_196.wav\n",
            "devel_197.wav\n",
            "devel_198.wav\n",
            "devel_199.wav\n",
            "devel_200.wav\n",
            "devel_201.wav\n",
            "devel_202.wav\n",
            "devel_203.wav\n",
            "devel_204.wav\n",
            "devel_205.wav\n",
            "devel_206.wav\n",
            "devel_207.wav\n",
            "devel_208.wav\n",
            "devel_209.wav\n",
            "devel_210.wav\n",
            "devel_211.wav\n",
            "devel_212.wav\n",
            "devel_213.wav\n",
            "devel_214.wav\n",
            "devel_215.wav\n",
            "devel_216.wav\n",
            "devel_217.wav\n",
            "devel_218.wav\n",
            "devel_219.wav\n",
            "devel_220.wav\n",
            "devel_221.wav\n",
            "devel_222.wav\n",
            "devel_223.wav\n",
            "devel_224.wav\n",
            "devel_225.wav\n",
            "devel_226.wav\n",
            "devel_227.wav\n",
            "devel_228.wav\n",
            "devel_229.wav\n",
            "devel_230.wav\n",
            "devel_231.wav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6ODTxRSCJDY"
      },
      "source": [
        "# Main Augmentation class\n",
        "\n",
        "class AudioAugmentation:\n",
        "    def read_audio_file(self, file_path):  #reading the audio file\n",
        "        input_length = 50000\n",
        "        data = librosa.core.load(file_path)[0]\n",
        "        if len(data) > input_length:\n",
        "            data1 = data[:input_length]           # split the audio into 2 \n",
        "            data2 = data[input_length:len(data)]\n",
        "            #data3 = data[2*input_length : len(data)]\n",
        "        else:\n",
        "            data1 = np.pad(data, (0, max(0, input_length - len(data))), \"constant\")\n",
        "            data2 = 0\n",
        "            #data3=0\n",
        "        return data1,data2\n",
        "\n",
        "    def write_audio_file(self, file, data, sample_rate=16000): #writing the augmented file into a new file name \n",
        "        librosa.output.write_wav(file, data, sample_rate)\n",
        "\n",
        "    def plot_time_series(self, data):   #plotting the augmented waveform\n",
        "        fig = plt.figure(figsize=(14, 8))\n",
        "        plt.title('Raw wave ')\n",
        "        plt.ylabel('Amplitude')\n",
        "        plt.plot(np.linspace(0, 1, len(data)), data)\n",
        "        plt.show()\n",
        "\n",
        "    def add_noise(self, data):   #adding a uniform noise\n",
        "        noise = np.random.randn(len(data))\n",
        "        data_noise = data + 0.005 * noise\n",
        "        return data_noise\n",
        "\n",
        "    def shift(self, data):\n",
        "        return np.roll(data, 1600)\n",
        "\n",
        "    def stretch(self, data, rate=1):\n",
        "        input_length = 16000\n",
        "        data = librosa.effects.time_stretch(data, rate)\n",
        "        if len(data) > input_length:\n",
        "            data = data[:input_length]\n",
        "        else: \n",
        "            data = np.pad(data, (0, max(0, input_length - len(data))), \"constant\")\n",
        "        return data\n",
        "\n",
        "    # We can use the function below for augmentation\n",
        "      \n",
        "    def augment(self,data):   # Apart from the function coded above , augmentation using Audiomentation\n",
        "        augment = Compose([AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.010, p=1),  # ADD gaussian noice of a small amplitude\n",
        "                           #TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
        "                           #PitchShift(min_semitones=-4, max_semitones=4, p=0.5), not changing the pitch because the pitch of cough might have information for the model\n",
        "                           Shift(min_fraction=-0.1, max_fraction=0.1,rollover=False, p=1), #shifting the audio\n",
        "                           FrequencyMask(min_frequency_band=0.0, max_frequency_band=0.5, p=0.5), #frequency mask with a probability 0.5\n",
        "                           ])\n",
        "        augmented_samples = augment(data, sample_rate=16000)\n",
        "        return augmented_samples\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1oYir8eXSAH"
      },
      "source": [
        "aa = AudioAugmentation()\n",
        "samplerate=16000  # All the data provided to us has a sample_rate of 16000 , hence the augmented file should have the same\n",
        " \n",
        "# Read and show sound\n",
        "data = aa.read_audio_file(\"/content/drive/MyDrive/ComParE2021/dist/wav/train_001.wav\")\n",
        " \n",
        "data1 = data[0]\n",
        "data2 = data[1]\n",
        "#data3 = data[2]\n",
        " \n",
        "# Adding uniform noise to sound\n",
        "# data_noise = aa.add_noise(data[0])\n",
        "# aa.plot_time_series(data_noise)\n",
        " \n",
        "# Shifting the sound\n",
        "# data_roll = aa.shift(data_noise)\n",
        "# aa.plot_time_series(data_roll)\n",
        " \n",
        "# Stretching the sound\n",
        "# data_stretch = aa.stretch(data[0], 0.8)\n",
        "# aa.plot_time_series(data_stretch)\n",
        " \n",
        "# Augmentation using audioAugment library\n",
        " \n",
        "data_aug1=aa.augment(data1)\n",
        "#aa.plot_time_series(data_aug1)\n",
        " \n",
        "data_aug2=aa.augment(data2)\n",
        "#aa.plot_time_series(data_aug2)\n",
        " \n",
        "#data_aug3=aa.augment(data3)\n",
        " \n",
        "sf.write('/content/drive/MyDrive/ComParE2021/output/val1_cough1.wav', data1,samplerate,format='wav')\n",
        "sf.write('/content/drive/MyDrive/ComParE2021/output/val1_cough2.wav', data2,samplerate,format='wav')\n",
        "\n",
        "sf.write('/content/drive/MyDrive/ComParE2021/output/val1_aug_cough1.wav', data_aug1,samplerate,format='wav')\n",
        "sf.write('/content/drive/MyDrive/ComParE2021/output/val1_aug_cough2.wav', data_aug2,samplerate,format='wav')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7HSTHMbJcC5"
      },
      "source": [
        "#Augmenting and writing into new folder\n",
        "\n",
        "input_directory = '/content/drive/MyDrive/ComParE2021/dist/wav'\n",
        "output_directory = '/content/drive/MyDrive/ComParE2021/data/Augmented_train'\n",
        "i=1\n",
        "for file in sorted(glob.glob('/content/drive/MyDrive/ComParE2021/dist/wav/train_***.wav')):\n",
        "\n",
        "  aa = AudioAugmentation()\n",
        "  samplerate=16000  \n",
        "  data = aa.read_audio_file(file)\n",
        "  data1 = data[0]\n",
        "  data2 = data[1]\n",
        " \n",
        "  data_aug1=aa.augment(data1)\n",
        "  data_aug2=aa.augment(data2)\n",
        "  \n",
        "  sf.write(f'/content/drive/MyDrive/ComParE2021/data/Augmented_train/train_{i:0>3d}_cough1.wav', data1,samplerate,format='wav')\n",
        "  sf.write(f'/content/drive/MyDrive/ComParE2021/data/Augmented_train/train_{i:0>3d}_cough2.wav', data2,samplerate,format='wav')\n",
        "  # sf.write(f'/content/drive/MyDrive/ComParE2021/data/Augmented_train/train_{i:0>3d}_cough3.wav', data3,samplerate,format='wav')\n",
        "  sf.write(f'/content/drive/MyDrive/ComParE2021/data/Augmented_train/train_{i:0>3d}_aug_cough1.wav', data_aug1,samplerate,format='wav')\n",
        "  sf.write(f'/content/drive/MyDrive/ComParE2021/data/Augmented_train/train_{i:0>3d}_aug_cough2.wav', data_aug2,samplerate,format='wav')\n",
        "  # sf.write(f'/content/drive/MyDrive/ComParE2021/data/Augmented_train/train_{i:0>3d}_aug_cough3.wav', data_aug3,samplerate,format='wav')\n",
        "  i=i+1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "licvih6EHZtu"
      },
      "source": [
        "# audio of devel 001\n",
        "from IPython.display import Audio\n",
        "Audio('/content/drive/MyDrive/ComParE2021/output/val1_aug_cough2.wav', rate=16000)  #the val 1 data provided to us"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXfmgU6vV8mV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}