{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xbow_feature.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HrithikNambiar/COVID-19-Cough-Detection/blob/main/xbow_feature.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlOz_I4kA99W",
        "outputId": "ac07cd21-9e98-4112-fef0-b4790cfb99dc"
      },
      "source": [
        "cd '/content/drive/MyDrive/ComParE2021'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ComParE2021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hs6i8euvCFn4",
        "outputId": "1bfa1bce-3b53-41f6-970b-7edc0e845280"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "activate           \u001b[0m\u001b[01;34mdist\u001b[0m/                             \u001b[01;34mnotebooks\u001b[0m/   \u001b[01;34mresults\u001b[0m/\n",
            "\u001b[01;34maudeep_workspace\u001b[0m/  \u001b[01;34mend2you_files\u001b[0m/                    \u001b[01;34mopensmile\u001b[0m/   \u001b[01;34mscripts\u001b[0m/\n",
            "\u001b[01;34maugmented_dist\u001b[0m/    \u001b[01;34mfeatures\u001b[0m/                         \u001b[01;34mopenxbow\u001b[0m/    smile.log\n",
            "\u001b[01;34mdata\u001b[0m/              \u001b[01;34mfeatures_2\u001b[0m/                       params.yaml  \u001b[01;34msrc\u001b[0m/\n",
            "\u001b[01;34mdata_2\u001b[0m/            Miniconda3-4.5.4-Linux-x86_64.sh  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAEVQfZNCGF7"
      },
      "source": [
        "!pip install -U PyYAML\n",
        "!pip install liac-arff\n",
        "!pip install -U scikit-learn scipy matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmKfK07oVbEG"
      },
      "source": [
        "Feature extraction using open XBoW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_CX4QPkCPuF"
      },
      "source": [
        "import os, yaml\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKG85DmVCSy0"
      },
      "source": [
        "params = {}\n",
        "with open('params.yaml') as f:\n",
        "    p = yaml.load(f, Loader=yaml.FullLoader)\n",
        "    params = p['XBOW']\n",
        "\n",
        "conf_attributes_map = {'ComParE_2016': 'n1[65]2[65]c'}\n",
        "\n",
        "# Paths\n",
        "os_features_folder = '/content/drive/MyDrive/ComParE2021/features_2/opensmile'\n",
        "features_folder = '/content/drive/MyDrive/ComParE2021/features_2/openXBoW'  #saved here.\n",
        "\n",
        "os.makedirs(features_folder, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keUPa_ANGmU5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11917975-b983-4fb2-942e-bd83ed1e176e"
      },
      "source": [
        "for dir in os.listdir(os_features_folder):\n",
        "  print(dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ComParE_2016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk1Z6flBCYvt"
      },
      "source": [
        "# Compute BoAW representations from openSMILE LLDs\n",
        "for dir in os.listdir(os_features_folder):\n",
        "    for csize in params['csize']:\n",
        "        for num_assignments in params['num_assignments']:\n",
        "            for part in ['train', 'val', 'test']:\n",
        "                output_dir = os.path.join(features_folder, dir, str(csize), str(num_assignments))\n",
        "                output_file_boaw = os.path.join(output_dir, f'{part}.arff')\n",
        "                os.makedirs(output_dir, exist_ok=True)\n",
        "                if dir in conf_attributes_map:\n",
        "                    xbow_config = f'-i {os.path.join(os_features_folder, dir, part + \"_lld.arff\")} -attributes {conf_attributes_map[dir]} -o {output_file_boaw}'\n",
        "                    if part=='train':\n",
        "                        xbow_config += f' -standardizeInput -size {csize} -a {num_assignments} -log -B {os.path.join(output_dir, \"codebook\")}'\n",
        "                    else:\n",
        "                        xbow_config += f' -b {os.path.join(output_dir, \"codebook\")}'\n",
        "                    os.system('java -Xmx12000m -jar ./openxbow/openXBOW.jar -writeName ' + xbow_config)\n",
        "                else:\n",
        "                    print(f'{dir} not mapped to attribute config. Mapped confs: {conf_attributes_map}.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr467va2C6dK"
      },
      "source": [
        "**SVM+ Compare BoAW**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCcod4pnDLcu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74a9f87d-a0f8-4646-ba3b-c69b4a8a3087"
      },
      "source": [
        "!python -m src.svm openXBoW # change FEATURE_BASE in src.svm to ./dist/features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6294398907103825\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.84      0.97      0.90       183\n",
            "    positive       0.70      0.29      0.41        48\n",
            "\n",
            "    accuracy                           0.83       231\n",
            "   macro avg       0.77      0.63      0.66       231\n",
            "weighted avg       0.81      0.83      0.80       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[177   6]\n",
            " [ 34  14]]\n",
            "Generating test predictions for optimised parameters {'estimator': 'LinearSVC(C=0.01, max_iter=10000, random_state=42)', 'estimator__C': '0.01', 'estimator__class_weight': 'None', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'None'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.60724043715847\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.84      0.80      0.82       183\n",
            "    positive       0.35      0.42      0.38        48\n",
            "\n",
            "    accuracy                           0.72       231\n",
            "   macro avg       0.59      0.61      0.60       231\n",
            "weighted avg       0.74      0.72      0.73       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[146  37]\n",
            " [ 28  20]]\n",
            "Generating test predictions for optimised parameters {'estimator': 'LinearSVC(C=0.001, max_iter=10000, random_state=42)', 'estimator__C': '0.001', 'estimator__class_weight': 'None', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6234631147540983\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.84      0.93      0.88       183\n",
            "    positive       0.56      0.31      0.40        48\n",
            "\n",
            "    accuracy                           0.81       231\n",
            "   macro avg       0.70      0.62      0.64       231\n",
            "weighted avg       0.78      0.81      0.78       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[171  12]\n",
            " [ 33  15]]\n",
            "Generating test predictions for optimised parameters {'estimator': 'LinearSVC(C=0.01, max_iter=10000, random_state=42)', 'estimator__C': '0.01', 'estimator__class_weight': 'None', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'None'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6511270491803278\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.78      0.82       183\n",
            "    positive       0.38      0.52      0.44        48\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.62      0.65      0.63       231\n",
            "weighted avg       0.76      0.73      0.74       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[143  40]\n",
            " [ 23  25]]\n",
            "Generating test predictions for optimised parameters {'estimator': \"LinearSVC(C=0.001, class_weight='balanced', max_iter=10000, random_state=42)\", 'estimator__C': '0.001', 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6466871584699454\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.81      0.83       183\n",
            "    positive       0.40      0.48      0.44        48\n",
            "\n",
            "    accuracy                           0.74       231\n",
            "   macro avg       0.63      0.65      0.64       231\n",
            "weighted avg       0.76      0.74      0.75       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[149  34]\n",
            " [ 25  23]]\n",
            "Generating test predictions for optimised parameters {'estimator': \"LinearSVC(C=1e-05, class_weight='balanced', max_iter=10000, random_state=42)\", 'estimator__C': '1e-05', 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'None'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6729849726775956\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.87      0.83      0.85       183\n",
            "    positive       0.44      0.52      0.48        48\n",
            "\n",
            "    accuracy                           0.76       231\n",
            "   macro avg       0.65      0.67      0.66       231\n",
            "weighted avg       0.78      0.76      0.77       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[151  32]\n",
            " [ 23  25]]\n",
            "Generating test predictions for optimised parameters {'estimator': 'LinearSVC(C=0.001, max_iter=10000, random_state=42)', 'estimator__C': '0.001', 'estimator__class_weight': 'None', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6752049180327868\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.87      0.81      0.84       183\n",
            "    positive       0.43      0.54      0.48        48\n",
            "\n",
            "    accuracy                           0.75       231\n",
            "   macro avg       0.65      0.68      0.66       231\n",
            "weighted avg       0.78      0.75      0.76       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[148  35]\n",
            " [ 22  26]]\n",
            "Generating test predictions for optimised parameters {'estimator': \"LinearSVC(C=0.01, class_weight='balanced', max_iter=10000, random_state=42)\", 'estimator__C': '0.01', 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6642759562841529\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.87      0.79      0.83       183\n",
            "    positive       0.40      0.54      0.46        48\n",
            "\n",
            "    accuracy                           0.74       231\n",
            "   macro avg       0.63      0.66      0.64       231\n",
            "weighted avg       0.77      0.74      0.75       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[144  39]\n",
            " [ 22  26]]\n",
            "Generating test predictions for optimised parameters {'estimator': \"LinearSVC(C=0.01, class_weight='balanced', max_iter=10000, random_state=42)\", 'estimator__C': '0.01', 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6543715846994536\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.81      0.83       183\n",
            "    positive       0.41      0.50      0.45        48\n",
            "\n",
            "    accuracy                           0.74       231\n",
            "   macro avg       0.63      0.65      0.64       231\n",
            "weighted avg       0.77      0.74      0.75       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[148  35]\n",
            " [ 24  24]]\n",
            "Generating test predictions for optimised parameters {'estimator': 'LinearSVC(C=0.001, max_iter=10000, random_state=42)', 'estimator__C': '0.001', 'estimator__class_weight': 'None', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.662568306010929\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.83      0.84       183\n",
            "    positive       0.43      0.50      0.46        48\n",
            "\n",
            "    accuracy                           0.76       231\n",
            "   macro avg       0.65      0.66      0.65       231\n",
            "weighted avg       0.77      0.76      0.76       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[151  32]\n",
            " [ 24  24]]\n",
            "Generating test predictions for optimised parameters {'estimator': 'LinearSVC(C=0.01, max_iter=10000, random_state=42)', 'estimator__C': '0.01', 'estimator__class_weight': 'None', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6724726775956285\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.87      0.80      0.84       183\n",
            "    positive       0.42      0.54      0.47        48\n",
            "\n",
            "    accuracy                           0.75       231\n",
            "   macro avg       0.64      0.67      0.65       231\n",
            "weighted avg       0.78      0.75      0.76       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[147  36]\n",
            " [ 22  26]]\n",
            "Generating test predictions for optimised parameters {'estimator': 'LinearSVC(C=0.01, max_iter=10000, random_state=42)', 'estimator__C': '0.01', 'estimator__class_weight': 'None', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6623975409836066\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.85      0.93      0.89       183\n",
            "    positive       0.59      0.40      0.48        48\n",
            "\n",
            "    accuracy                           0.82       231\n",
            "   macro avg       0.72      0.66      0.68       231\n",
            "weighted avg       0.80      0.82      0.80       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[170  13]\n",
            " [ 29  19]]\n",
            "Generating test predictions for optimised parameters {'estimator': 'LinearSVC(C=0.01, max_iter=10000, random_state=42)', 'estimator__C': '0.01', 'estimator__class_weight': 'None', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'None'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6067281420765027\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.84      0.78      0.81       183\n",
            "    positive       0.34      0.44      0.38        48\n",
            "\n",
            "    accuracy                           0.71       231\n",
            "   macro avg       0.59      0.61      0.59       231\n",
            "weighted avg       0.74      0.71      0.72       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[142  41]\n",
            " [ 27  21]]\n",
            "Generating test predictions for optimised parameters {'estimator': \"LinearSVC(C=0.1, class_weight='balanced', max_iter=10000, random_state=42)\", 'estimator__C': '0.1', 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6516393442622951\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.80      0.83       183\n",
            "    positive       0.40      0.50      0.44        48\n",
            "\n",
            "    accuracy                           0.74       231\n",
            "   macro avg       0.63      0.65      0.64       231\n",
            "weighted avg       0.76      0.74      0.75       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[147  36]\n",
            " [ 24  24]]\n",
            "Generating test predictions for optimised parameters {'estimator': \"LinearSVC(C=0.1, class_weight='balanced', max_iter=10000, random_state=42)\", 'estimator__C': '0.1', 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'None'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.67400956284153\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.87      0.87       183\n",
            "    positive       0.49      0.48      0.48        48\n",
            "\n",
            "    accuracy                           0.79       231\n",
            "   macro avg       0.68      0.67      0.68       231\n",
            "weighted avg       0.79      0.79      0.79       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[159  24]\n",
            " [ 25  23]]\n",
            "Generating test predictions for optimised parameters {'estimator': \"LinearSVC(C=0.1, class_weight='balanced', max_iter=10000, random_state=42)\", 'estimator__C': '0.1', 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'None'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTxzzIciDHu0"
      },
      "source": [
        "**SVM + BoAW + Augmented data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1647Ji9Dd_m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "955f5d9e-0efb-47e1-9320-d5834d7ec1cb"
      },
      "source": [
        "!python -m src.svm openXBoW  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6434426229508197\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.79      0.82       183\n",
            "    positive       0.38      0.50      0.43        48\n",
            "\n",
            "    accuracy                           0.73       231\n",
            "   macro avg       0.62      0.64      0.63       231\n",
            "weighted avg       0.76      0.73      0.74       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[144  39]\n",
            " [ 24  24]]\n",
            "Generating test predictions for optimised parameters {'estimator': \"LinearSVC(C=0.001, class_weight='balanced', max_iter=10000, random_state=42)\", 'estimator__C': '0.001', 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.5922131147540983\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.83      0.93      0.88       183\n",
            "    positive       0.50      0.25      0.33        48\n",
            "\n",
            "    accuracy                           0.79       231\n",
            "   macro avg       0.66      0.59      0.61       231\n",
            "weighted avg       0.76      0.79      0.76       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[171  12]\n",
            " [ 36  12]]\n",
            "Generating test predictions for optimised parameters {'estimator': 'LinearSVC(C=0.1, max_iter=10000, random_state=42)', 'estimator__C': '0.1', 'estimator__class_weight': 'None', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "UAR: 0.6004098360655737\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.83      0.95      0.89       183\n",
            "    positive       0.57      0.25      0.35        48\n",
            "\n",
            "    accuracy                           0.81       231\n",
            "   macro avg       0.70      0.60      0.62       231\n",
            "weighted avg       0.78      0.81      0.77       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[174   9]\n",
            " [ 36  12]]\n",
            "Generating test predictions for optimised parameters {'estimator': \"LinearSVC(C=0.1, class_weight='balanced', max_iter=10000, random_state=42)\", 'estimator__C': '0.1', 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'None'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6010928961748634\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.54      0.66       183\n",
            "    positive       0.27      0.67      0.39        48\n",
            "\n",
            "    accuracy                           0.56       231\n",
            "   macro avg       0.57      0.60      0.52       231\n",
            "weighted avg       0.74      0.56      0.60       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[98 85]\n",
            " [16 32]]\n",
            "Generating test predictions for optimised parameters {'estimator': \"LinearSVC(C=0.0001, class_weight='balanced', max_iter=10000, random_state=42)\", 'estimator__C': '0.0001', 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.613558743169399\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.62      0.72       183\n",
            "    positive       0.30      0.60      0.40        48\n",
            "\n",
            "    accuracy                           0.62       231\n",
            "   macro avg       0.58      0.61      0.56       231\n",
            "weighted avg       0.74      0.62      0.65       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[114  69]\n",
            " [ 19  29]]\n",
            "Generating test predictions for optimised parameters {'estimator': 'LinearSVC(C=0.0001, max_iter=10000, random_state=42)', 'estimator__C': '0.0001', 'estimator__class_weight': 'None', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "UAR: 0.6031420765027322\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.83      0.96      0.89       183\n",
            "    positive       0.60      0.25      0.35        48\n",
            "\n",
            "    accuracy                           0.81       231\n",
            "   macro avg       0.71      0.60      0.62       231\n",
            "weighted avg       0.78      0.81      0.78       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[175   8]\n",
            " [ 36  12]]\n",
            "Generating test predictions for optimised parameters {'estimator': 'LinearSVC(C=0.01, max_iter=10000, random_state=42)', 'estimator__C': '0.01', 'estimator__class_weight': 'None', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6352459016393442\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.85      0.77      0.81       183\n",
            "    positive       0.36      0.50      0.42        48\n",
            "\n",
            "    accuracy                           0.71       231\n",
            "   macro avg       0.61      0.64      0.62       231\n",
            "weighted avg       0.75      0.71      0.73       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[141  42]\n",
            " [ 24  24]]\n",
            "Generating test predictions for optimised parameters {'estimator': \"LinearSVC(C=0.001, class_weight='balanced', max_iter=10000, random_state=42)\", 'estimator__C': '0.001', 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'None'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6391734972677596\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.72      0.78       183\n",
            "    positive       0.34      0.56      0.43        48\n",
            "\n",
            "    accuracy                           0.68       231\n",
            "   macro avg       0.60      0.64      0.60       231\n",
            "weighted avg       0.75      0.68      0.71       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[131  52]\n",
            " [ 21  27]]\n",
            "Generating test predictions for optimised parameters {'estimator': 'LinearSVC(C=0.001, max_iter=10000, random_state=42)', 'estimator__C': '0.001', 'estimator__class_weight': 'None', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6244877049180328\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.64      0.74       183\n",
            "    positive       0.31      0.60      0.41        48\n",
            "\n",
            "    accuracy                           0.64       231\n",
            "   macro avg       0.58      0.62      0.57       231\n",
            "weighted avg       0.75      0.64      0.67       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[118  65]\n",
            " [ 19  29]]\n",
            "Generating test predictions for optimised parameters {'estimator': \"LinearSVC(C=1e-05, class_weight='balanced', max_iter=10000, random_state=42)\", 'estimator__C': '1e-05', 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6079234972677596\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.85      0.72      0.78       183\n",
            "    positive       0.32      0.50      0.39        48\n",
            "\n",
            "    accuracy                           0.67       231\n",
            "   macro avg       0.58      0.61      0.58       231\n",
            "weighted avg       0.74      0.67      0.69       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[131  52]\n",
            " [ 24  24]]\n",
            "Generating test predictions for optimised parameters {'estimator': \"LinearSVC(C=0.0001, class_weight='balanced', max_iter=10000, random_state=42)\", 'estimator__C': '0.0001', 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6246584699453552\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.88      0.54      0.67       183\n",
            "    positive       0.29      0.71      0.41        48\n",
            "\n",
            "    accuracy                           0.58       231\n",
            "   macro avg       0.58      0.62      0.54       231\n",
            "weighted avg       0.75      0.58      0.62       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[99 84]\n",
            " [14 34]]\n",
            "Generating test predictions for optimised parameters {'estimator': \"LinearSVC(C=1e-05, class_weight='balanced', max_iter=10000, random_state=42)\", 'estimator__C': '1e-05', 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.6246584699453552\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.88      0.54      0.67       183\n",
            "    positive       0.29      0.71      0.41        48\n",
            "\n",
            "    accuracy                           0.58       231\n",
            "   macro avg       0.58      0.62      0.54       231\n",
            "weighted avg       0.75      0.58      0.62       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[99 84]\n",
            " [14 34]]\n",
            "Generating test predictions for optimised parameters {'estimator': \"LinearSVC(C=1e-05, class_weight='balanced', max_iter=10000, random_state=42)\", 'estimator__C': '1e-05', 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "UAR: 0.5860655737704918\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.84      0.67      0.75       183\n",
            "    positive       0.29      0.50      0.36        48\n",
            "\n",
            "    accuracy                           0.64       231\n",
            "   macro avg       0.56      0.59      0.55       231\n",
            "weighted avg       0.72      0.64      0.67       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[123  60]\n",
            " [ 24  24]]\n",
            "Generating test predictions for optimised parameters {'estimator': \"LinearSVC(C=0.0001, class_weight='balanced', max_iter=10000, random_state=42)\", 'estimator__C': '0.0001', 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "UAR: 0.59375\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.84      0.67      0.74       183\n",
            "    positive       0.29      0.52      0.37        48\n",
            "\n",
            "    accuracy                           0.64       231\n",
            "   macro avg       0.57      0.59      0.56       231\n",
            "weighted avg       0.73      0.64      0.67       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[122  61]\n",
            " [ 23  25]]\n",
            "Generating test predictions for optimised parameters {'estimator': 'LinearSVC(C=0.0001, max_iter=10000, random_state=42)', 'estimator__C': '0.0001', 'estimator__class_weight': 'None', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "UAR: 0.6147540983606556\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.87      0.56      0.68       183\n",
            "    positive       0.29      0.67      0.40        48\n",
            "\n",
            "    accuracy                           0.58       231\n",
            "   macro avg       0.58      0.61      0.54       231\n",
            "weighted avg       0.75      0.58      0.62       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[103  80]\n",
            " [ 16  32]]\n",
            "Generating test predictions for optimised parameters {'estimator': \"LinearSVC(C=1e-05, class_weight='balanced', max_iter=10000, random_state=42)\", 'estimator__C': '1e-05', 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yknkPeQreecA"
      },
      "source": [
        "!python -m src.svm opensmile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vBtpRQDiM_I"
      },
      "source": [
        "generating auDeep features on augmented data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myDNzSIEl4KU"
      },
      "source": [
        "# !cp data/test/*.wav augmented_dist/wav"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzv2BRg9mb5Q"
      },
      "source": [
        "# !cp data/train/*.wav augmented_dist/wav"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "PWcg1XoTu_S9",
        "outputId": "abe01fc4-8179-4f0b-a778-2483437a2238"
      },
      "source": [
        "# downgrade numpy temporarily to avoid errors with auDeep\n",
        "!pip install numpy==1.15.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/92/c01d3a6c58ceab0e6ec36ad3af41bc076014cc916afcb979ab4c9558f347/numpy-1.15.0-cp37-cp37m-manylinux1_x86_64.whl (13.8MB)\n",
            "\u001b[K     |████████████████████████████████| 13.9MB 283kB/s \n",
            "\u001b[31mERROR: umap-learn 0.5.1 has requirement numpy>=1.17, but you'll have numpy 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tifffile 2021.3.5 has requirement numpy>=1.15.1, but you'll have numpy 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: scipy 1.6.1 has requirement numpy>=1.16.5, but you'll have numpy 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pyerfa 1.7.2 has requirement numpy>=1.16, but you'll have numpy 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pyarrow 3.0.0 has requirement numpy>=1.16.6, but you'll have numpy 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement numpy>=1.16.0, but you'll have numpy 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pandas 1.1.5 has requirement numpy>=1.15.4, but you'll have numpy 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: jaxlib 0.1.62+cuda110 has requirement numpy>=1.16, but you'll have numpy 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement numpy>=1.15.4, but you'll have numpy 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: astropy 4.2 has requirement numpy>=1.17, but you'll have numpy 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "Successfully installed numpy-1.15.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sbfIOp-aiTsG",
        "outputId": "7a3ab0a5-e2b7-479a-ecc9-a4dffb37f47c"
      },
      "source": [
        "!pip install auDeep"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting auDeep\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/42/7418bc5871abbf9b6741bd2b50ffca1e676229ef51d216ebf4d80a68c88f/auDeep-0.9.4-py3-none-any.whl (167kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 7.7MB/s \n",
            "\u001b[?25hCollecting tensorflow-gpu<2,>=1.15.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/b5/adc281ce4e631251c749d342793795832026edf9035df81c3813ef33fad2/tensorflow_gpu-1.15.5-cp37-cp37m-manylinux2010_x86_64.whl (411.0MB)\n",
            "\u001b[K     |████████████████████████████████| 411.0MB 24kB/s \n",
            "\u001b[?25hCollecting netCDF4==1.4.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/10/350fa9b13f2fe6494efb8e8c79f007722a927a456ce4ad52b78fa36849b4/netCDF4-1.4.2-cp37-cp37m-manylinux1_x86_64.whl (3.9MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 22.5MB/s \n",
            "\u001b[?25hCollecting cliff>=3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/d6/7d9acb68a77acd140be7fececb7f2701b2a29d2da9c54184cb8f93509590/cliff-3.7.0-py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.1MB/s \n",
            "\u001b[?25hCollecting pysoundfile>=0.9\n",
            "  Downloading https://files.pythonhosted.org/packages/2a/b3/0b871e5fd31b9a8e54b4ee359384e705a1ca1e2870706d2f081dc7cc1693/PySoundFile-0.9.0.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: liac-arff>=2.4 in /usr/local/lib/python3.7/dist-packages (from auDeep) (2.5.0)\n",
            "Collecting xarray==0.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/56/ed26c1bd0868b3db73c02ead628b283fed8deda687584f0dc271e61ea977/xarray-0.10.0-py2.py3-none-any.whl (353kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 32.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.7/dist-packages (from auDeep) (1.6.1)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.7/dist-packages (from auDeep) (1.1.5)\n",
            "Requirement already satisfied: matplotlib>=3.2 in /usr/local/lib/python3.7/dist-packages (from auDeep) (3.3.4)\n",
            "Requirement already satisfied: scikit-learn>=0.23 in /usr/local/lib/python3.7/dist-packages (from auDeep) (0.24.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu<2,>=1.15.2->auDeep) (0.36.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu<2,>=1.15.2->auDeep) (1.1.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.3MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: h5py<=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu<2,>=1.15.2->auDeep) (2.10.0)\n",
            "Collecting numpy<1.19.0,>=1.16.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/c6/58e517e8b1fb192725cfa23c01c2e60e4e6699314ee9684a1c5f5c9b27e1/numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 15.7MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 16.5MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu<2,>=1.15.2->auDeep) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu<2,>=1.15.2->auDeep) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu<2,>=1.15.2->auDeep) (3.12.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu<2,>=1.15.2->auDeep) (3.3.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu<2,>=1.15.2->auDeep) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu<2,>=1.15.2->auDeep) (1.32.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu<2,>=1.15.2->auDeep) (0.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu<2,>=1.15.2->auDeep) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu<2,>=1.15.2->auDeep) (0.2.0)\n",
            "Collecting cftime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/e0/3e120cca16571c5ee3b35f1ed432c2aae5dc91e2b789e8b9c3a70e721ea0/cftime-1.4.1-cp37-cp37m-manylinux2014_x86_64.whl (313kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 45.2MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/48/69046506f6ac61c1eaa9a0d42d22d54673b69e176d30ca98e3f61513e980/pbr-5.5.1-py2.py3-none-any.whl (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 19.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff>=3.3->auDeep) (2.1.0)\n",
            "Collecting stevedore>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/49/b602307aeac3df3384ff1fcd05da9c0376c622a6c48bb5325f28ab165b57/stevedore-3.3.0-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from cliff>=3.3->auDeep) (2.4.7)\n",
            "Collecting cmd2>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/8b/15061b32332bb35ea2a2f6263d0f616779d576e82739ec8e7fcf3c94abf5/cmd2-1.5.0-py3-none-any.whl (133kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 31.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from cliff>=3.3->auDeep) (5.4.1)\n",
            "Requirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.7/dist-packages (from pysoundfile>=0.9->auDeep) (1.14.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->auDeep) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->auDeep) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2->auDeep) (1.3.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2->auDeep) (7.0.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2->auDeep) (0.10.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23->auDeep) (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23->auDeep) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu<2,>=1.15.2->auDeep) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu<2,>=1.15.2->auDeep) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu<2,>=1.15.2->auDeep) (54.0.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from PrettyTable>=0.7.2->cliff>=3.3->auDeep) (3.7.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from PrettyTable>=0.7.2->cliff>=3.3->auDeep) (0.2.5)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a7/2c/4c64579f847bd5d539803c8b909e54ba087a79d01bb3aba433a95879a6c5/pyperclip-1.8.2.tar.gz\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff>=3.3->auDeep) (20.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=0.6->pysoundfile>=0.9->auDeep) (2.20)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->PrettyTable>=0.7.2->cliff>=3.3->auDeep) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->PrettyTable>=0.7.2->cliff>=3.3->auDeep) (3.4.1)\n",
            "Building wheels for collected packages: gast, pyperclip\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=8c199c9c9afa7d9828408afcb8ca79b1cab01b50bb201901240d8e6141054400\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-cp37-none-any.whl size=11107 sha256=3e051376bfe053d611c0faa6fb80ca6972ac011df4c21c8055429e757ca8bdc7\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/af/b8/3407109267803f4015e1ee2ff23be0c8c19ce4008665931ee1\n",
            "Successfully built gast pyperclip\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.18.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorboard~=2.4, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement tensorflow-estimator<2.5.0,>=2.4.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, keras-applications, gast, tensorboard, tensorflow-estimator, tensorflow-gpu, cftime, netCDF4, pbr, stevedore, colorama, pyperclip, cmd2, cliff, pysoundfile, xarray, auDeep\n",
            "  Found existing installation: numpy 1.15.0\n",
            "    Uninstalling numpy-1.15.0:\n",
            "      Successfully uninstalled numpy-1.15.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: xarray 0.15.1\n",
            "    Uninstalling xarray-0.15.1:\n",
            "      Successfully uninstalled xarray-0.15.1\n",
            "Successfully installed auDeep-0.9.4 cftime-1.4.1 cliff-3.7.0 cmd2-1.5.0 colorama-0.4.4 gast-0.2.2 keras-applications-1.0.8 netCDF4-1.4.2 numpy-1.18.5 pbr-5.5.1 pyperclip-1.8.2 pysoundfile-0.9.0.post1 stevedore-3.3.0 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.5 xarray-0.10.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z43J4FR1iTnZ",
        "outputId": "bd65e049-4606-4188-a04d-1ff2eb1d69d8"
      },
      "source": [
        "# set in scripts/auDeep.sh\n",
        "# audio_base= \"augmented_dist/\"  # use \"augmented_dist/\" for running on augmented data\n",
        "\n",
        "!bash scripts/auDeep.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "audeep preprocess --parser audeep.backend.parsers.compare21.Compare21Parser --basedir dist/ --output audeep_workspace/input/spectrograms/ComParE21-0.08-0.04-128-30.nc --window-width 0.08 --window-overlap 0.04 --fixed-length 8 --center-fixed --clip-below -30 --mel-spectrum 128\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:51: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:70: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "[ERROR] audeep - No module named 'audeep.backend.parsers.compare21'\n",
            "\u001b[0maudeep preprocess --parser audeep.backend.parsers.compare21.Compare21Parser --basedir dist/ --output audeep_workspace/input/spectrograms/ComParE21-0.08-0.04-128-45.nc --window-width 0.08 --window-overlap 0.04 --fixed-length 8 --center-fixed --clip-below -45 --mel-spectrum 128\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:51: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:70: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "[ERROR] audeep - No module named 'audeep.backend.parsers.compare21'\n",
            "\u001b[0maudeep preprocess --parser audeep.backend.parsers.compare21.Compare21Parser --basedir dist/ --output audeep_workspace/input/spectrograms/ComParE21-0.08-0.04-128-60.nc --window-width 0.08 --window-overlap 0.04 --fixed-length 8 --center-fixed --clip-below -60 --mel-spectrum 128\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:51: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:70: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "[ERROR] audeep - No module named 'audeep.backend.parsers.compare21'\n",
            "\u001b[0maudeep preprocess --parser audeep.backend.parsers.compare21.Compare21Parser --basedir dist/ --output audeep_workspace/input/spectrograms/ComParE21-0.08-0.04-128-75.nc --window-width 0.08 --window-overlap 0.04 --fixed-length 8 --center-fixed --clip-below -75 --mel-spectrum 128\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:51: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:70: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "[ERROR] audeep - No module named 'audeep.backend.parsers.compare21'\n",
            "\u001b[0maudeep t-rae train --input audeep_workspace/input/spectrograms/ComParE21-0.08-0.04-128-30.nc --run-name audeep_workspace/output/ComParE21-0.08-0.04-128-30/t-2x256-x-b --tempdir audeep_workspace/output/ComParE21-0.08-0.04-128-30/t-2x256-x-b/tmp --num-epochs 64 --batch-size 512 --learning-rate 0.001 --keep-prob 0.8 --cell GRU --num-layers 2 --num-units 256 --bidirectional-decoder\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:51: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:70: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "[ERROR] audeep - failed to open data set file at audeep_workspace/input/spectrograms/ComParE21-0.08-0.04-128-30.nc\n",
            "\u001b[0maudeep t-rae train --input audeep_workspace/input/spectrograms/ComParE21-0.08-0.04-128-45.nc --run-name audeep_workspace/output/ComParE21-0.08-0.04-128-45/t-2x256-x-b --tempdir audeep_workspace/output/ComParE21-0.08-0.04-128-45/t-2x256-x-b/tmp --num-epochs 64 --batch-size 512 --learning-rate 0.001 --keep-prob 0.8 --cell GRU --num-layers 2 --num-units 256 --bidirectional-decoder\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:51: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:70: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "[ERROR] audeep - failed to open data set file at audeep_workspace/input/spectrograms/ComParE21-0.08-0.04-128-45.nc\n",
            "\u001b[0maudeep t-rae train --input audeep_workspace/input/spectrograms/ComParE21-0.08-0.04-128-60.nc --run-name audeep_workspace/output/ComParE21-0.08-0.04-128-60/t-2x256-x-b --tempdir audeep_workspace/output/ComParE21-0.08-0.04-128-60/t-2x256-x-b/tmp --num-epochs 64 --batch-size 512 --learning-rate 0.001 --keep-prob 0.8 --cell GRU --num-layers 2 --num-units 256 --bidirectional-decoder\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:51: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:70: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "[ERROR] audeep - failed to open data set file at audeep_workspace/input/spectrograms/ComParE21-0.08-0.04-128-60.nc\n",
            "\u001b[0maudeep t-rae train --input audeep_workspace/input/spectrograms/ComParE21-0.08-0.04-128-75.nc --run-name audeep_workspace/output/ComParE21-0.08-0.04-128-75/t-2x256-x-b --tempdir audeep_workspace/output/ComParE21-0.08-0.04-128-75/t-2x256-x-b/tmp --num-epochs 64 --batch-size 512 --learning-rate 0.001 --keep-prob 0.8 --cell GRU --num-layers 2 --num-units 256 --bidirectional-decoder\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:51: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:70: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "[ERROR] audeep - failed to open data set file at audeep_workspace/input/spectrograms/ComParE21-0.08-0.04-128-75.nc\n",
            "\u001b[0maudeep t-rae generate --model-dir audeep_workspace/output/ComParE21-0.08-0.04-128-30/t-2x256-x-b/logs --input audeep_workspace/input/spectrograms/ComParE21-0.08-0.04-128-30.nc --output audeep_workspace/output/ComParE21-0.08-0.04-128-30/t-2x256-x-b/representations.nc\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:51: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:70: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "[ERROR] audeep - failed to open data set at audeep_workspace/input/spectrograms/ComParE21-0.08-0.04-128-30.nc\n",
            "\u001b[0maudeep t-rae generate --model-dir audeep_workspace/output/ComParE21-0.08-0.04-128-45/t-2x256-x-b/logs --input audeep_workspace/input/spectrograms/ComParE21-0.08-0.04-128-45.nc --output audeep_workspace/output/ComParE21-0.08-0.04-128-45/t-2x256-x-b/representations.nc\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:51: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:70: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "[ERROR] audeep - failed to open data set at audeep_workspace/input/spectrograms/ComParE21-0.08-0.04-128-45.nc\n",
            "\u001b[0maudeep t-rae generate --model-dir audeep_workspace/output/ComParE21-0.08-0.04-128-60/t-2x256-x-b/logs --input audeep_workspace/input/spectrograms/ComParE21-0.08-0.04-128-60.nc --output audeep_workspace/output/ComParE21-0.08-0.04-128-60/t-2x256-x-b/representations.nc\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:51: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:70: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "[ERROR] audeep - failed to open data set at audeep_workspace/input/spectrograms/ComParE21-0.08-0.04-128-60.nc\n",
            "\u001b[0maudeep t-rae generate --model-dir audeep_workspace/output/ComParE21-0.08-0.04-128-75/t-2x256-x-b/logs --input audeep_workspace/input/spectrograms/ComParE21-0.08-0.04-128-75.nc --output audeep_workspace/output/ComParE21-0.08-0.04-128-75/t-2x256-x-b/representations.nc\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:51: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:70: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "[ERROR] audeep - failed to open data set at audeep_workspace/input/spectrograms/ComParE21-0.08-0.04-128-75.nc\n",
            "\u001b[0maudeep fuse --input audeep_workspace/output/ComParE21-0.08-0.04-128*/*/representations.nc --output audeep_workspace/output/ComParE21-fused/representations.nc\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:51: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:70: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "[ERROR] audeep - failed to open data set at audeep_workspace/output/ComParE21-0.08-0.04-128*/*/representations.nc\n",
            "\u001b[0maudeep export --input audeep_workspace/output/ComParE21-0.08-0.04-128-30/t-2x256-x-b/representations.nc --format CSV --labels-last --output audeep_workspace/csv/partitions --name -30\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:51: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:70: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "[ERROR] audeep - failed to open data set at audeep_workspace/output/ComParE21-0.08-0.04-128-30/t-2x256-x-b/representations.nc\n",
            "\u001b[0mcp: cannot stat 'audeep_workspace/csv/partitions/train/-30.csv': No such file or directory\n",
            "cp: cannot stat 'audeep_workspace/csv/partitions/devel/-30.csv': No such file or directory\n",
            "cp: cannot stat 'audeep_workspace/csv/partitions/test/-30.csv': No such file or directory\n",
            "audeep export --input audeep_workspace/output/ComParE21-0.08-0.04-128-45/t-2x256-x-b/representations.nc --format CSV --labels-last --output audeep_workspace/csv/partitions --name -45\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:51: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:70: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "[ERROR] audeep - failed to open data set at audeep_workspace/output/ComParE21-0.08-0.04-128-45/t-2x256-x-b/representations.nc\n",
            "\u001b[0mcp: cannot stat 'audeep_workspace/csv/partitions/train/-45.csv': No such file or directory\n",
            "cp: cannot stat 'audeep_workspace/csv/partitions/devel/-45.csv': No such file or directory\n",
            "cp: cannot stat 'audeep_workspace/csv/partitions/test/-45.csv': No such file or directory\n",
            "audeep export --input audeep_workspace/output/ComParE21-0.08-0.04-128-60/t-2x256-x-b/representations.nc --format CSV --labels-last --output audeep_workspace/csv/partitions --name -60\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:51: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:70: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "[ERROR] audeep - failed to open data set at audeep_workspace/output/ComParE21-0.08-0.04-128-60/t-2x256-x-b/representations.nc\n",
            "\u001b[0mcp: cannot stat 'audeep_workspace/csv/partitions/train/-60.csv': No such file or directory\n",
            "cp: cannot stat 'audeep_workspace/csv/partitions/devel/-60.csv': No such file or directory\n",
            "cp: cannot stat 'audeep_workspace/csv/partitions/test/-60.csv': No such file or directory\n",
            "audeep export --input audeep_workspace/output/ComParE21-0.08-0.04-128-75/t-2x256-x-b/representations.nc --format CSV --labels-last --output audeep_workspace/csv/partitions --name -75\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:51: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:70: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "[ERROR] audeep - failed to open data set at audeep_workspace/output/ComParE21-0.08-0.04-128-75/t-2x256-x-b/representations.nc\n",
            "\u001b[0mcp: cannot stat 'audeep_workspace/csv/partitions/train/-75.csv': No such file or directory\n",
            "cp: cannot stat 'audeep_workspace/csv/partitions/devel/-75.csv': No such file or directory\n",
            "cp: cannot stat 'audeep_workspace/csv/partitions/test/-75.csv': No such file or directory\n",
            "audeep export --input audeep_workspace/output/ComParE21-fused/representations.nc --format CSV --labels-last --output audeep_workspace/csv/partitions --name fused\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:51: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/audeep/backend/training/base.py:70: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "[ERROR] audeep - failed to open data set at audeep_workspace/output/ComParE21-fused/representations.nc\n",
            "\u001b[0mcp: cannot stat 'audeep_workspace/csv/partitions/train/fused.csv': No such file or directory\n",
            "cp: cannot stat 'audeep_workspace/csv/partitions/devel/fused.csv': No such file or directory\n",
            "cp: cannot stat 'audeep_workspace/csv/partitions/test/fused.csv': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wWGgLeEin7U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eyrqqow0iQ_m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAdU-h_0iQwK"
      },
      "source": [
        "training on auDeep\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rytrrfxLefNZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f14f9336-6f7e-4a9b-eb2b-2432e2df73a2"
      },
      "source": [
        "!python -m src.svm auDeep"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
            "UAR: 0.610655737704918\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.85      0.72      0.78       183\n",
            "    positive       0.32      0.50      0.39        48\n",
            "\n",
            "    accuracy                           0.68       231\n",
            "   macro avg       0.58      0.61      0.58       231\n",
            "weighted avg       0.74      0.68      0.70       231\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[132  51]\n",
            " [ 24  24]]\n",
            "Generating test predictions for optimised parameters {'estimator': \"LinearSVC(C=0.1, class_weight='balanced', max_iter=10000, random_state=42)\", 'estimator__C': '0.1', 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 10000, 'scaler': 'StandardScaler()'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1a6R2J7y9rkZWY_SyloMCwmm8qdQAliCz/ComParE2021/src/svm.py\", line 179, in <module>\n",
            "    run_svm(dirpath, result_dir, params)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1a6R2J7y9rkZWY_SyloMCwmm8qdQAliCz/ComParE2021/src/svm.py\", line 83, in run_svm\n",
            "    train_y = train_df.values[:, label_index].astype(str)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\", line 5345, in values\n",
            "    return self._mgr.as_array(transpose=self._AXIS_REVERSED)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\", line 862, in as_array\n",
            "    arr = self._interleave(dtype=dtype, na_value=na_value)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\", line 901, in _interleave\n",
            "    arr = blk.get_values(dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/internals/blocks.py\", line 219, in get_values\n",
            "    return self.values.astype(object)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P74KWnQohTDh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "522cfc64-8610-49cf-ae91-7a4a45dc9616"
      },
      "source": [
        "!python -m src.svm deepspectrum"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "/usr/bin/python3: Error while finding module specification for 'src.svm' (ModuleNotFoundError: No module named 'src')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2Ul_38ljlMF"
      },
      "source": [
        "Convert arff to csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf8F0dwhenD2"
      },
      "source": [
        "import json\n",
        "import glob\n",
        "import arff\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "OPENSMILE_FEATURES = '/content/drive/MyDrive/ComParE2021/features/opensmile'\n",
        "OPENXBOW_FEATURES = '/content/drive/MyDrive/ComParE2021/features/openXBoW'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6JxwNK7jpuE"
      },
      "source": [
        "if __name__=='__main__':\n",
        "    opensmile_arffs = sorted(glob.glob(f'{OPENSMILE_FEATURES}/**/*.arff', recursive=True))\n",
        "    for arff_file in opensmile_arffs:\n",
        "        with open(arff_file) as f:\n",
        "            arff_data = arff.load(f)\n",
        "            df = pd.DataFrame(data=arff_data['data'], columns=[attribute[0] for attribute in arff_data['attributes']])\n",
        "        target_folder = os.path.dirname(arff_file.replace('opensmile', 'opensmile_csv'))\n",
        "        os.makedirs(target_folder, exist_ok=True)\n",
        "        target = os.path.join(target_folder, f'{os.path.splitext(os.path.basename(arff_file))[0]}.csv')\n",
        "        df.to_csv(target, index=False)\n",
        "\n",
        "    openxbow_arffs = sorted(glob.glob(f'{OPENXBOW_FEATURES}/**/*.arff', recursive=True))\n",
        "    for arff_file in openxbow_arffs:\n",
        "        with open(arff_file) as f:\n",
        "            arff_data = arff.load(f)\n",
        "            df = pd.DataFrame(data=arff_data['data'], columns=[attribute[0] for attribute in arff_data['attributes']])\n",
        "        target_folder = os.path.dirname(arff_file.replace('openXBoW', 'openXBoW_csv'))\n",
        "        os.makedirs(target_folder, exist_ok=True)\n",
        "        target = os.path.join(target_folder, f'{os.path.splitext(os.path.basename(arff_file))[0]}.csv')\n",
        "        df.to_csv(target, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}